{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T13:14:01.273246Z",
     "iopub.status.busy": "2023-06-15T13:14:01.272770Z",
     "iopub.status.idle": "2023-06-15T13:14:01.286116Z",
     "shell.execute_reply": "2023-06-15T13:14:01.285154Z",
     "shell.execute_reply.started": "2023-06-15T13:14:01.273192Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from pickle import dump\n",
    "import tensorflow as tf\n",
    "from keras.applications import EfficientNetV2L\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
    "from keras.models import Model\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Encoder part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(directory):\n",
    "    \n",
    "  model = EfficientNetV2L()\n",
    "  model.layers.pop()\n",
    "  model = Model(inputs = model.inputs,outputs = model.layers[-1].output)\n",
    "  #print(model.summary())\n",
    "  features = dict()\n",
    "  for name in listdir(directory):\n",
    "    filename = directory +'/'+ name\n",
    "    image = load_img(filename,target_size = (480,480))\n",
    "    image = img_to_array(image)\n",
    "    image = image.reshape(1,image.shape[0],image.shape[1],image.shape[2])\n",
    "    image = preprocess_input(image)\n",
    "    feature = model.predict(image,verbose=1)\n",
    "    image_id = name.split('.')[0]\n",
    "    features[image_id] = feature\n",
    "    print(\"image name is : \"+name)\n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extract feature from images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "features = dict()\n",
    "features = extract_features('/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/flickr30k_images/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = '/kaggle/working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T11:46:45.161865Z",
     "iopub.status.busy": "2023-06-15T11:46:45.161095Z",
     "iopub.status.idle": "2023-06-15T11:46:46.138166Z",
     "shell.execute_reply": "2023-06-15T11:46:46.134321Z",
     "shell.execute_reply.started": "2023-06-15T11:46:45.161810Z"
    }
   },
   "outputs": [],
   "source": [
    "# store features in pickle\n",
    "import os\n",
    "import pickle\n",
    "pickle.dump(features, open(os.path.join(WORKING_DIR, 'features.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:26.217499Z",
     "iopub.status.busy": "2023-06-15T14:06:26.216413Z",
     "iopub.status.idle": "2023-06-15T14:06:26.520821Z",
     "shell.execute_reply": "2023-06-15T14:06:26.519636Z",
     "shell.execute_reply.started": "2023-06-15T14:06:26.217459Z"
    }
   },
   "outputs": [],
   "source": [
    "# load features from pickle\n",
    "import os\n",
    "import pickle\n",
    "with open(os.path.join('/kaggle/input/feature', 'features.pkl'), 'rb') as f:\n",
    "    features = pickle.load(f)\n",
    "    \n",
    "print(features['10002456'].shape)\n",
    "print(features['1000268201'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data PreProcessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:30.419982Z",
     "iopub.status.busy": "2023-06-15T14:06:30.419638Z",
     "iopub.status.idle": "2023-06-15T14:06:30.510473Z",
     "shell.execute_reply": "2023-06-15T14:06:30.509171Z",
     "shell.execute_reply.started": "2023-06-15T14:06:30.419954Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('/kaggle/input/d/nournirabi/results/', 'results_Copy.txt'), 'r') as f:\n",
    "    next(f)\n",
    "    desc = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:30.594394Z",
     "iopub.status.busy": "2023-06-15T14:06:30.593964Z",
     "iopub.status.idle": "2023-06-15T14:06:30.599140Z",
     "shell.execute_reply": "2023-06-15T14:06:30.598018Z",
     "shell.execute_reply.started": "2023-06-15T14:06:30.594368Z"
    }
   },
   "outputs": [],
   "source": [
    "#import lib we need\n",
    "import string\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:30.834672Z",
     "iopub.status.busy": "2023-06-15T14:06:30.834314Z",
     "iopub.status.idle": "2023-06-15T14:06:30.839944Z",
     "shell.execute_reply": "2023-06-15T14:06:30.838997Z",
     "shell.execute_reply.started": "2023-06-15T14:06:30.834642Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_document(filename):\n",
    "    file = open(filename,'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:30.849896Z",
     "iopub.status.busy": "2023-06-15T14:06:30.849442Z",
     "iopub.status.idle": "2023-06-15T14:06:30.862145Z",
     "shell.execute_reply": "2023-06-15T14:06:30.861185Z",
     "shell.execute_reply.started": "2023-06-15T14:06:30.849796Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_descriptions(filename):\n",
    "    # create mapping of image to captions\n",
    "    mapping = dict()\n",
    "   # process lines\n",
    "    for line in doc.split('\\n'):\n",
    "        if '\"' in line:\n",
    "            line = line.replace('\"','')\n",
    "        tokens = line.split( )\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "        image_id, caption = tokens[0], tokens[1:]\n",
    "        # remove extension from image ID\n",
    "        image_id = image_id.split('.')[0]\n",
    "        # convert caption list to string\n",
    "        caption = \" \".join(caption)\n",
    "        # create list if needed\n",
    "        if image_id not in mapping:\n",
    "            mapping[image_id] = []\n",
    "        # store the caption\n",
    "        mapping[image_id].append(caption)\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:31.014968Z",
     "iopub.status.busy": "2023-06-15T14:06:31.014554Z",
     "iopub.status.idle": "2023-06-15T14:06:31.025226Z",
     "shell.execute_reply": "2023-06-15T14:06:31.024436Z",
     "shell.execute_reply.started": "2023-06-15T14:06:31.014925Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_description(description):\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    for key,desc_list in description.items() :\n",
    "        for i in range(len(desc_list)):\n",
    "            desc = desc_list[i]\n",
    "            desc = desc.split()\n",
    "            desc = [word.lower() for word in desc]\n",
    "            desc = [word.translate(table) for word in desc]\n",
    "            desc = [word for word in desc if len(word) > 1]\n",
    "            desc = [word for word in desc if word.isalpha()]\n",
    "            desc_list[i] = ' '.join(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:31.082680Z",
     "iopub.status.busy": "2023-06-15T14:06:31.082340Z",
     "iopub.status.idle": "2023-06-15T14:06:31.088981Z",
     "shell.execute_reply": "2023-06-15T14:06:31.088155Z",
     "shell.execute_reply.started": "2023-06-15T14:06:31.082649Z"
    }
   },
   "outputs": [],
   "source": [
    "# Converting the loaded descriptions into a vocabulary of words\n",
    "\n",
    "def to_vocabulary(descriptions):\n",
    "    \n",
    "    # Build a list of all description strings\n",
    "    all_desc = set()\n",
    "    \n",
    "    for key in descriptions.keys():\n",
    "        \n",
    "        [all_desc.update(d.split()) for d in descriptions[key]]\n",
    "    \n",
    "    return all_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:31.272217Z",
     "iopub.status.busy": "2023-06-15T14:06:31.271925Z",
     "iopub.status.idle": "2023-06-15T14:06:31.277956Z",
     "shell.execute_reply": "2023-06-15T14:06:31.276916Z",
     "shell.execute_reply.started": "2023-06-15T14:06:31.272193Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_descriptions(descriptions , filename):\n",
    "    lines = list()\n",
    "    for key , desc_list in descriptions.items():\n",
    "        for desc in desc_list :\n",
    "            lines.append(key +' '+desc)\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename,'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:31.481579Z",
     "iopub.status.busy": "2023-06-15T14:06:31.481284Z",
     "iopub.status.idle": "2023-06-15T14:06:34.489133Z",
     "shell.execute_reply": "2023-06-15T14:06:34.487790Z",
     "shell.execute_reply.started": "2023-06-15T14:06:31.481555Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = '/kaggle/input/d/nournirabi/results/results_Copy.txt'\n",
    "# Loading descriptions\n",
    "doc = load_document(filename)\n",
    "\n",
    "# Cleaning the descriptions\n",
    "descriptions = load_descriptions(filename)\n",
    "clean_description(descriptions)\n",
    "\n",
    "# Summarizing the vocabulary\n",
    "vocabulary = to_vocabulary(descriptions)\n",
    "print('Vocabulary Size: %d' % len(vocabulary))\n",
    "\n",
    "# Saving to the file\n",
    "save_descriptions(descriptions, 'descriptions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:34.491983Z",
     "iopub.status.busy": "2023-06-15T14:06:34.491371Z",
     "iopub.status.idle": "2023-06-15T14:06:34.497115Z",
     "shell.execute_reply": "2023-06-15T14:06:34.496071Z",
     "shell.execute_reply.started": "2023-06-15T14:06:34.491936Z"
    }
   },
   "outputs": [],
   "source": [
    "def max_length(descriptions):\n",
    "    lines = to_lines(descriptions)\n",
    "    return max(len(d.split()) for d in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:34.498984Z",
     "iopub.status.busy": "2023-06-15T14:06:34.498356Z",
     "iopub.status.idle": "2023-06-15T14:06:34.687145Z",
     "shell.execute_reply": "2023-06-15T14:06:34.686308Z",
     "shell.execute_reply.started": "2023-06-15T14:06:34.498950Z"
    }
   },
   "outputs": [],
   "source": [
    "print(max_length(descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:34.690306Z",
     "iopub.status.busy": "2023-06-15T14:06:34.689873Z",
     "iopub.status.idle": "2023-06-15T14:06:34.696146Z",
     "shell.execute_reply": "2023-06-15T14:06:34.695183Z",
     "shell.execute_reply.started": "2023-06-15T14:06:34.690273Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_set(filename):\n",
    "    doc = load_document(filename)\n",
    "    dataset = list()\n",
    "    for line in doc.split('\\n'):\n",
    "        if '\"' in line:\n",
    "            line = line.replace('\"','')\n",
    "        if len(line) < 1:\n",
    "            continue\n",
    "        identifier = line.split('.')[0]\n",
    "        dataset.append(identifier)\n",
    "    return set(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:34.698388Z",
     "iopub.status.busy": "2023-06-15T14:06:34.697475Z",
     "iopub.status.idle": "2023-06-15T14:06:34.709472Z",
     "shell.execute_reply": "2023-06-15T14:06:34.708437Z",
     "shell.execute_reply.started": "2023-06-15T14:06:34.698356Z"
    }
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "def load_image_feature(filename,dataset):\n",
    "    all_feat = load(open(filename , 'rb'))\n",
    "    features = {k : all_feat[k] for k in dataset}\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:34.711726Z",
     "iopub.status.busy": "2023-06-15T14:06:34.711038Z",
     "iopub.status.idle": "2023-06-15T14:06:34.722743Z",
     "shell.execute_reply": "2023-06-15T14:06:34.721758Z",
     "shell.execute_reply.started": "2023-06-15T14:06:34.711697Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_clean_descriptions(filename , dataset):\n",
    "    doc = load_document(filename)\n",
    "    \n",
    "    discriptions = dict()\n",
    "\n",
    "    for line in doc.split('\\n'):\n",
    "        tokens = line.split( )\n",
    "        image_id, caption = tokens[0], tokens[1:]\n",
    "        # remove extension from image ID\n",
    "        #image_id = image_id.split('.')[0]\n",
    "        if image_id in dataset :\n",
    "            if image_id not in descriptions:\n",
    "                descriptions[image_id] = list()\n",
    "            desc = 'startseq ' +' '.join(caption)+' endseq'\n",
    "            descriptions[image_id].append(desc)\n",
    "            \n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:34.724610Z",
     "iopub.status.busy": "2023-06-15T14:06:34.724165Z",
     "iopub.status.idle": "2023-06-15T14:06:35.529251Z",
     "shell.execute_reply": "2023-06-15T14:06:35.528243Z",
     "shell.execute_reply.started": "2023-06-15T14:06:34.724580Z"
    }
   },
   "outputs": [],
   "source": [
    "train = load_set(filename)\n",
    "print(\"num of images : %d\" % len(train))\n",
    "#descriptions\n",
    "descs = load_clean_descriptions('/kaggle/working/descriptions.txt' , train)\n",
    "print(\"Descriptions : %d\" % len(descs))\n",
    "#features \n",
    "features = load_image_feature('/kaggle/input/feature/features.pkl',train)\n",
    "print(\"Features : %d\" % len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:35.531261Z",
     "iopub.status.busy": "2023-06-15T14:06:35.530895Z",
     "iopub.status.idle": "2023-06-15T14:06:35.536547Z",
     "shell.execute_reply": "2023-06-15T14:06:35.535441Z",
     "shell.execute_reply.started": "2023-06-15T14:06:35.531228Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_lines(descriptions):\n",
    "    all_desc = list()\n",
    "    for key in descriptions.keys():\n",
    "        [all_desc.append(d) for d in descriptions[key]]\n",
    "    return all_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:35.539114Z",
     "iopub.status.busy": "2023-06-15T14:06:35.538350Z",
     "iopub.status.idle": "2023-06-15T14:06:35.555937Z",
     "shell.execute_reply": "2023-06-15T14:06:35.555045Z",
     "shell.execute_reply.started": "2023-06-15T14:06:35.539084Z"
    }
   },
   "outputs": [],
   "source": [
    "def creat_tokenizer(descriptions):\n",
    "    lines = to_lines(descriptions)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:35.560549Z",
     "iopub.status.busy": "2023-06-15T14:06:35.560267Z",
     "iopub.status.idle": "2023-06-15T14:06:41.399070Z",
     "shell.execute_reply": "2023-06-15T14:06:41.398077Z",
     "shell.execute_reply.started": "2023-06-15T14:06:35.560526Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# tokenize the text\n",
    "tokenizer = creat_tokenizer(descs)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:41.402395Z",
     "iopub.status.busy": "2023-06-15T14:06:41.400854Z",
     "iopub.status.idle": "2023-06-15T14:06:41.407809Z",
     "shell.execute_reply": "2023-06-15T14:06:41.406724Z",
     "shell.execute_reply.started": "2023-06-15T14:06:41.402358Z"
    }
   },
   "outputs": [],
   "source": [
    "print(type(vocab_size))\n",
    "print(type(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:41.409824Z",
     "iopub.status.busy": "2023-06-15T14:06:41.409469Z",
     "iopub.status.idle": "2023-06-15T14:06:41.419807Z",
     "shell.execute_reply": "2023-06-15T14:06:41.418785Z",
     "shell.execute_reply.started": "2023-06-15T14:06:41.409792Z"
    }
   },
   "outputs": [],
   "source": [
    "def max_length(descriptions):\n",
    "    lines = to_lines(descriptions)\n",
    "    return max(len(d.split()) for d in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:06:41.422083Z",
     "iopub.status.busy": "2023-06-15T14:06:41.421699Z",
     "iopub.status.idle": "2023-06-15T14:06:41.762710Z",
     "shell.execute_reply": "2023-06-15T14:06:41.761621Z",
     "shell.execute_reply.started": "2023-06-15T14:06:41.422049Z"
    }
   },
   "outputs": [],
   "source": [
    "print(max_length(descriptions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Split**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:23:22.889614Z",
     "iopub.status.busy": "2023-06-15T14:23:22.889260Z",
     "iopub.status.idle": "2023-06-15T14:23:22.898268Z",
     "shell.execute_reply": "2023-06-15T14:23:22.897182Z",
     "shell.execute_reply.started": "2023-06-15T14:23:22.889586Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_sequences(tokenizer, max_length, desc_list, feature):\n",
    "    x_1, x_2, y = list(), list(), list()\n",
    "    # move through each description for the image\n",
    "    for desc in desc_list:\n",
    "        # encode the sequence\n",
    "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "        # divide one sequence into various X,y pairs\n",
    "        for i in range(1, len(seq)):\n",
    "                # divide into input and output pair\n",
    "                in_seq, out_seq = seq[:i], seq[i]\n",
    "                # pad input sequence\n",
    "                in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "                # encode output sequence\n",
    "                out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "                # store\n",
    "                x_1.append(feature)\n",
    "                x_2.append(in_seq)\n",
    "                y.append(out_seq)\n",
    "    return np.array(x_1), np.array(x_2), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:23:23.332632Z",
     "iopub.status.busy": "2023-06-15T14:23:23.331978Z",
     "iopub.status.idle": "2023-06-15T14:23:23.338420Z",
     "shell.execute_reply": "2023-06-15T14:23:23.337321Z",
     "shell.execute_reply.started": "2023-06-15T14:23:23.332599Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_generator(descriptions, features, tokenizer, max_length): \n",
    "    while 1:\n",
    "        for key, description_list in descriptions.items():\n",
    "            #retrieve photo features\n",
    "            feature = features[key][0]\n",
    "            inp_image, inp_seq, op_word = create_sequences(tokenizer, max_length, description_list, feature)\n",
    "            yield [[inp_image, inp_seq], op_word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Create Model (Decoder Part)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**import lib we need**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T14:49:34.855644Z",
     "iopub.status.busy": "2023-06-15T14:49:34.854779Z",
     "iopub.status.idle": "2023-06-15T14:49:34.861823Z",
     "shell.execute_reply": "2023-06-15T14:49:34.860765Z",
     "shell.execute_reply.started": "2023-06-15T14:49:34.855601Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T15:54:07.383742Z",
     "iopub.status.busy": "2023-06-15T15:54:07.383369Z",
     "iopub.status.idle": "2023-06-15T15:54:07.393547Z",
     "shell.execute_reply": "2023-06-15T15:54:07.392652Z",
     "shell.execute_reply.started": "2023-06-15T15:54:07.383712Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "  # define the captioning model\n",
    "    \n",
    "def define_model(vocab_size, max_length):\n",
    "    \n",
    "    # features from the CNN model compressed from 2048 to 256 nodes\n",
    "    \n",
    "    inputs1 = Input(shape=(1000,))\n",
    "    \n",
    "    fe1 = Dropout(0.5)(inputs1)\n",
    "    fe2 = Dense(370, activation='relu')(fe1)\n",
    "    \n",
    "    # LSTM sequence model\n",
    "    \n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    se1 = Embedding(vocab_size, 370, mask_zero=True)(inputs2)\n",
    "    se2 = add([fe2, se1])\n",
    "    se3 = (LSTM(512,return_sequences = True))(se2)\n",
    "    se4 = Dropout(0.5)(se3)\n",
    "    \n",
    " \n",
    "    decoder = Dense(512, activation='relu')(se4)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(decoder)\n",
    "   \n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam' , metrics=['accuracy'])\n",
    "    # summarize model\n",
    "    print(model.summary())\n",
    "    plot_model(model, show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T15:54:11.554099Z",
     "iopub.status.busy": "2023-06-15T15:54:11.553088Z",
     "iopub.status.idle": "2023-06-15T15:54:13.898198Z",
     "shell.execute_reply": "2023-06-15T15:54:13.896555Z",
     "shell.execute_reply.started": "2023-06-15T15:54:11.554060Z"
    }
   },
   "outputs": [],
   "source": [
    "# train our model\n",
    "max_length = 74\n",
    "vocab_size = 19738\n",
    "model = define_model(vocab_size, max_length)\n",
    "epochs = 10\n",
    "j =21\n",
    "steps = len(descs)\n",
    "# creating a directory named models to save our models\n",
    "for i in range(epochs):\n",
    "    generator = data_generator(descriptions,features, tokenizer, max_length)\n",
    "    history = model.fit_generator(generator, epochs =1, steps_per_epoch= steps, verbose=1)\n",
    "    #j = j+1\n",
    "    #model.save(\"model21/model_\" + str(j) + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
