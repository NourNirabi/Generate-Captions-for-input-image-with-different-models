{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_D845C0NlHh"
   },
   "outputs": [],
   "source": [
    "!mkdir  'weights3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-07-13T09:18:56.573233Z",
     "iopub.status.busy": "2023-07-13T09:18:56.572774Z",
     "iopub.status.idle": "2023-07-13T09:19:12.879258Z",
     "shell.execute_reply": "2023-07-13T09:19:12.877683Z",
     "shell.execute_reply.started": "2023-07-13T09:18:56.573185Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:19:12.883849Z",
     "iopub.status.busy": "2023-07-13T09:19:12.882795Z",
     "iopub.status.idle": "2023-07-13T09:19:19.061610Z",
     "shell.execute_reply": "2023-07-13T09:19:19.059675Z",
     "shell.execute_reply.started": "2023-07-13T09:19:12.883792Z"
    }
   },
   "source": [
    "!gdown --id 1Zs93aWxHykVlWvDnh9OAMf1Vb3Adlwej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:19:57.045265Z",
     "iopub.status.busy": "2023-07-13T09:19:57.043612Z",
     "iopub.status.idle": "2023-07-13T09:20:10.730693Z",
     "shell.execute_reply": "2023-07-13T09:20:10.729084Z",
     "shell.execute_reply.started": "2023-07-13T09:19:57.045199Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:20:10.734219Z",
     "iopub.status.busy": "2023-07-13T09:20:10.733688Z",
     "iopub.status.idle": "2023-07-13T09:20:23.119831Z",
     "shell.execute_reply": "2023-07-13T09:20:23.118089Z",
     "shell.execute_reply.started": "2023-07-13T09:20:10.734168Z"
    },
    "id": "nqxz7wY-r_YW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "from keras.utils import plot_model\n",
    "from keras.applications.xception import Xception\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.models import Model\n",
    "import string\n",
    "import numpy as np\n",
    "from pickle import load\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM ,GRU\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout, Reshape, Lambda, Concatenate\n",
    "from keras.layers import Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from time import time\n",
    "\n",
    "emb_dim = 50\n",
    "snaphot_folder = '/kaggle/working/weights3'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:20:23.123155Z",
     "iopub.status.busy": "2023-07-13T09:20:23.122177Z",
     "iopub.status.idle": "2023-07-13T09:20:23.131405Z",
     "shell.execute_reply": "2023-07-13T09:20:23.129653Z",
     "shell.execute_reply.started": "2023-07-13T09:20:23.123110Z"
    },
    "id": "aTktpRTKL3um"
   },
   "outputs": [],
   "source": [
    "def progressBar(value, endvalue, bar_length=20,job='Job'):\n",
    "\n",
    "    percent = float(value) / endvalue\n",
    "    arrow = '-' * int(round(percent * bar_length)-1) + '>'\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "\n",
    "    sys.stdout.write(\"\\r{0} Completion: [{1}] {2}%\".format(job,arrow + spaces, int(round(percent * 100))))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:20:23.134989Z",
     "iopub.status.busy": "2023-07-13T09:20:23.134330Z",
     "iopub.status.idle": "2023-07-13T09:20:23.151301Z",
     "shell.execute_reply": "2023-07-13T09:20:23.150244Z",
     "shell.execute_reply.started": "2023-07-13T09:20:23.134950Z"
    },
    "id": "bXKycXfgsu-4"
   },
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "\tfile = open(filename, 'r')\n",
    "\ttext = file.read()\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "def load_set(filenames):\n",
    "\t# process line by line\n",
    "    dataset= list()\n",
    "    for filename in filenames:\n",
    "\t\t# get the image identifier\n",
    "        identifier = filename.split('.')[0]\n",
    "        dataset.append(identifier)\n",
    "    return list(set(dataset))\n",
    "\n",
    "def load_photo_features(filename, dataset):\n",
    "\t# load all features\n",
    "\tall_features = load(open(filename, 'rb'))\n",
    "\t# filter features\n",
    "\tfeatures = {k: all_features[k] for k in dataset}\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:20:23.153383Z",
     "iopub.status.busy": "2023-07-13T09:20:23.152980Z",
     "iopub.status.idle": "2023-07-13T09:20:23.453875Z",
     "shell.execute_reply": "2023-07-13T09:20:23.452553Z",
     "shell.execute_reply.started": "2023-07-13T09:20:23.153346Z"
    },
    "id": "RqzC7Gpys5aQ"
   },
   "outputs": [],
   "source": [
    "doc = load_doc(\"/kaggle/input/cleaning-results/results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:20:23.455723Z",
     "iopub.status.busy": "2023-07-13T09:20:23.455306Z",
     "iopub.status.idle": "2023-07-13T09:20:24.146788Z",
     "shell.execute_reply": "2023-07-13T09:20:24.145329Z",
     "shell.execute_reply.started": "2023-07-13T09:20:23.455689Z"
    },
    "id": "-3gtV0JGuISS",
    "outputId": "9aebb568-d7f7-4041-d807-639c0de7a37e"
   },
   "outputs": [],
   "source": [
    "descriptions = {}\n",
    "for line in doc.split('\\n'):\n",
    "    try:\n",
    "        tokens = line.split()\n",
    "        image_id, image_desc = tokens[0], tokens[1:]\n",
    "        # extract filename from image id\n",
    "        image_id = image_id.split('.')[0]\n",
    "        # convert description tokens back to string\n",
    "        image_desc = ' '.join(image_desc)\n",
    "        if image_id not in descriptions:\n",
    "            descriptions[image_id] = list()\n",
    "        descriptions[image_id].append(image_desc)\n",
    "    except :\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:20:24.148920Z",
     "iopub.status.busy": "2023-07-13T09:20:24.148405Z",
     "iopub.status.idle": "2023-07-13T09:20:24.159892Z",
     "shell.execute_reply": "2023-07-13T09:20:24.158671Z",
     "shell.execute_reply.started": "2023-07-13T09:20:24.148878Z"
    },
    "id": "_M_knsZuuLwv",
    "outputId": "a25d6f2e-280d-4ccd-93dc-0a33345e5862"
   },
   "outputs": [],
   "source": [
    "descriptions['5500138655']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:20:24.162840Z",
     "iopub.status.busy": "2023-07-13T09:20:24.161882Z",
     "iopub.status.idle": "2023-07-13T09:20:24.537300Z",
     "shell.execute_reply": "2023-07-13T09:20:24.536242Z",
     "shell.execute_reply.started": "2023-07-13T09:20:24.162784Z"
    },
    "id": "CI8QsVPoupJC",
    "outputId": "0e2a50bf-106d-48a6-e63a-a2bf91e5260d"
   },
   "outputs": [],
   "source": [
    "print(next(iter(descriptions)),descriptions[next(iter(descriptions))])\n",
    "\n",
    "x = plt.imread('/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/'+next(iter(descriptions))+'.jpg')\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:20:24.539471Z",
     "iopub.status.busy": "2023-07-13T09:20:24.538898Z",
     "iopub.status.idle": "2023-07-13T09:20:24.550444Z",
     "shell.execute_reply": "2023-07-13T09:20:24.549049Z",
     "shell.execute_reply.started": "2023-07-13T09:20:24.539433Z"
    },
    "id": "uyIUuvVEwJrw"
   },
   "outputs": [],
   "source": [
    "def clean_data(pairs):\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for key, desc_list in descriptions.items():\n",
    "        for i in range(len(desc_list)):\n",
    "            desc = desc_list[i]\n",
    "            # tokenize\n",
    "            desc = desc.split()\n",
    "            # convert to lower case\n",
    "            desc = [word.lower() for word in desc]\n",
    "            # remove punctuation from each token\n",
    "            desc = [w.translate(table) for w in desc]\n",
    "            # remove hanging 's' and 'a'\n",
    "            desc = [word for word in desc if len(word)>0]\n",
    "            # remove tokens with numbers in them\n",
    "            desc = [word for word in desc if word.isalpha()]\n",
    "            # store as string\n",
    "            desc_list[i] =  ' '.join(desc)\n",
    "\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:20:24.557416Z",
     "iopub.status.busy": "2023-07-13T09:20:24.556426Z",
     "iopub.status.idle": "2023-07-13T09:20:27.298546Z",
     "shell.execute_reply": "2023-07-13T09:20:27.297175Z",
     "shell.execute_reply.started": "2023-07-13T09:20:24.557376Z"
    },
    "id": "PcKQe7QqwLLF",
    "outputId": "4d825afb-9ad6-45e3-d1e4-31b9146e981f"
   },
   "outputs": [],
   "source": [
    "descriptions_clean = clean_data(descriptions)\n",
    "descriptions[next(iter(descriptions_clean))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:20:27.300841Z",
     "iopub.status.busy": "2023-07-13T09:20:27.300458Z",
     "iopub.status.idle": "2023-07-13T09:20:27.308643Z",
     "shell.execute_reply": "2023-07-13T09:20:27.307026Z",
     "shell.execute_reply.started": "2023-07-13T09:20:27.300806Z"
    },
    "id": "k9hFdFvzwd1d"
   },
   "outputs": [],
   "source": [
    "start_token = '<startseq>'\n",
    "end_token = '<endseq>'\n",
    "def add_end_start_tokens(descriptions):\n",
    "    for key in descriptions:\n",
    "        for i in range(len(descriptions[key])):\n",
    "            descriptions[key][i] = start_token + ' ' + descriptions[key][i] + ' ' + end_token\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:20:27.311141Z",
     "iopub.status.busy": "2023-07-13T09:20:27.310711Z",
     "iopub.status.idle": "2023-07-13T09:20:27.471634Z",
     "shell.execute_reply": "2023-07-13T09:20:27.470352Z",
     "shell.execute_reply.started": "2023-07-13T09:20:27.311075Z"
    },
    "id": "-MdQBXhPwmEO",
    "outputId": "c82ff98d-db30-449f-ceda-cc6fd77a3d60"
   },
   "outputs": [],
   "source": [
    "descriptions_tokenSE = add_end_start_tokens(descriptions_clean)\n",
    "descriptions_tokenSE[next(iter(descriptions_tokenSE))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xz46KH9Oxftq"
   },
   "source": [
    "#### Loading train captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:20:27.473602Z",
     "iopub.status.busy": "2023-07-13T09:20:27.473216Z",
     "iopub.status.idle": "2023-07-13T09:20:27.480485Z",
     "shell.execute_reply": "2023-07-13T09:20:27.478733Z",
     "shell.execute_reply.started": "2023-07-13T09:20:27.473566Z"
    },
    "id": "hcBgqG53xhPS"
   },
   "outputs": [],
   "source": [
    "def load_train_test(descriptions, dataset):\n",
    "    dataset_ = {}\n",
    "    for image_id in dataset:\n",
    "        dataset_[image_id] = descriptions[image_id]\n",
    "\n",
    "    return dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:20:27.483712Z",
     "iopub.status.busy": "2023-07-13T09:20:27.482864Z",
     "iopub.status.idle": "2023-07-13T09:21:05.217557Z",
     "shell.execute_reply": "2023-07-13T09:21:05.215723Z",
     "shell.execute_reply.started": "2023-07-13T09:20:27.483654Z"
    },
    "id": "kbwt3H3F43dO"
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "mypath ='/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/'\n",
    "filenames = next(walk(mypath), (None, None, []))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:05.219974Z",
     "iopub.status.busy": "2023-07-13T09:21:05.219553Z",
     "iopub.status.idle": "2023-07-13T09:21:05.226534Z",
     "shell.execute_reply": "2023-07-13T09:21:05.225339Z",
     "shell.execute_reply.started": "2023-07-13T09:21:05.219941Z"
    },
    "id": "kN_xvbIb2Q4o",
    "outputId": "aa6bceb4-c628-4745-fa5a-a9e59401a0cd"
   },
   "outputs": [],
   "source": [
    "print(type(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:05.228875Z",
     "iopub.status.busy": "2023-07-13T09:21:05.228420Z",
     "iopub.status.idle": "2023-07-13T09:21:05.244057Z",
     "shell.execute_reply": "2023-07-13T09:21:05.242829Z",
     "shell.execute_reply.started": "2023-07-13T09:21:05.228837Z"
    },
    "id": "InDbJN6S5i5a",
    "outputId": "e90d9faa-8274-43b4-aa39-8562e33d8925"
   },
   "outputs": [],
   "source": [
    "print(filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:05.246647Z",
     "iopub.status.busy": "2023-07-13T09:21:05.246090Z",
     "iopub.status.idle": "2023-07-13T09:21:05.270582Z",
     "shell.execute_reply": "2023-07-13T09:21:05.269235Z",
     "shell.execute_reply.started": "2023-07-13T09:21:05.246588Z"
    },
    "id": "QQXnNJSNJ-Xr",
    "outputId": "c2cbbf44-6d2f-4994-c1d6-40300a8b0fa8"
   },
   "outputs": [],
   "source": [
    "idxx=0\n",
    "for i in range(len(filenames)):\n",
    "    if '.jpg' in filenames[i]:\n",
    "        pass\n",
    "    else:\n",
    "        idxx=i\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:05.272896Z",
     "iopub.status.busy": "2023-07-13T09:21:05.272057Z",
     "iopub.status.idle": "2023-07-13T09:21:05.284283Z",
     "shell.execute_reply": "2023-07-13T09:21:05.282935Z",
     "shell.execute_reply.started": "2023-07-13T09:21:05.272853Z"
    },
    "id": "oZuUIxJNKhBM"
   },
   "outputs": [],
   "source": [
    "x=filenames[idxx]\n",
    "filenames.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:05.288021Z",
     "iopub.status.busy": "2023-07-13T09:21:05.286819Z",
     "iopub.status.idle": "2023-07-13T09:21:05.302396Z",
     "shell.execute_reply": "2023-07-13T09:21:05.301217Z",
     "shell.execute_reply.started": "2023-07-13T09:21:05.287967Z"
    }
   },
   "outputs": [],
   "source": [
    "split = int(0.8*len(filenames))\n",
    "filenames_train = filenames[:split]\n",
    "filenames_testval = filenames[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:05.305359Z",
     "iopub.status.busy": "2023-07-13T09:21:05.304942Z",
     "iopub.status.idle": "2023-07-13T09:21:05.318021Z",
     "shell.execute_reply": "2023-07-13T09:21:05.316831Z",
     "shell.execute_reply.started": "2023-07-13T09:21:05.305324Z"
    }
   },
   "outputs": [],
   "source": [
    "split = int(0.9*len(filenames_testval))\n",
    "filenames_test = filenames_testval[:split]\n",
    "filenames_val = filenames_testval[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:05.320865Z",
     "iopub.status.busy": "2023-07-13T09:21:05.320052Z",
     "iopub.status.idle": "2023-07-13T09:21:05.342076Z",
     "shell.execute_reply": "2023-07-13T09:21:05.340916Z",
     "shell.execute_reply.started": "2023-07-13T09:21:05.320824Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(filenames_train))\n",
    "print(len(filenames_test))\n",
    "print(len(filenames_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:05.344902Z",
     "iopub.status.busy": "2023-07-13T09:21:05.343939Z",
     "iopub.status.idle": "2023-07-13T09:21:05.379611Z",
     "shell.execute_reply": "2023-07-13T09:21:05.378086Z",
     "shell.execute_reply.started": "2023-07-13T09:21:05.344861Z"
    },
    "id": "xbIW894J37ho"
   },
   "outputs": [],
   "source": [
    "train_imgs_names = load_set(filenames_train)\n",
    "test_imgs_names = load_set(filenames_test)\n",
    "val_imgs_names = load_set(filenames_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:05.382410Z",
     "iopub.status.busy": "2023-07-13T09:21:05.381585Z",
     "iopub.status.idle": "2023-07-13T09:21:05.417726Z",
     "shell.execute_reply": "2023-07-13T09:21:05.416269Z",
     "shell.execute_reply.started": "2023-07-13T09:21:05.382369Z"
    }
   },
   "outputs": [],
   "source": [
    "train_descriptions = load_train_test(descriptions_tokenSE, train_imgs_names)\n",
    "test_descriptions = load_train_test(descriptions_tokenSE, test_imgs_names)\n",
    "val_descriptions = load_train_test(descriptions_tokenSE, val_imgs_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:05.420263Z",
     "iopub.status.busy": "2023-07-13T09:21:05.419803Z",
     "iopub.status.idle": "2023-07-13T09:21:05.427669Z",
     "shell.execute_reply": "2023-07-13T09:21:05.425877Z",
     "shell.execute_reply.started": "2023-07-13T09:21:05.420227Z"
    },
    "id": "dvRhL3q85-0v"
   },
   "outputs": [],
   "source": [
    "print(len(train_descriptions))\n",
    "print(len(test_descriptions))\n",
    "print(len(val_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:05.429862Z",
     "iopub.status.busy": "2023-07-13T09:21:05.429407Z",
     "iopub.status.idle": "2023-07-13T09:21:05.594898Z",
     "shell.execute_reply": "2023-07-13T09:21:05.592951Z",
     "shell.execute_reply.started": "2023-07-13T09:21:05.429827Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(train_descriptions, open('train_descriptions.pkl', 'wb'))\n",
    "pickle.dump(test_descriptions, open('test_descriptions.pkl', 'wb'))\n",
    "pickle.dump(val_descriptions, open('val_descriptions.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:05.599189Z",
     "iopub.status.busy": "2023-07-13T09:21:05.598769Z",
     "iopub.status.idle": "2023-07-13T09:21:05.715401Z",
     "shell.execute_reply": "2023-07-13T09:21:05.713936Z",
     "shell.execute_reply.started": "2023-07-13T09:21:05.599158Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/working/train_descriptions.pkl','rb') as f:\n",
    "    train_descriptions= pickle.load(f)\n",
    "with open('/kaggle/working/test_descriptions.pkl','rb') as f:\n",
    "    test_descriptions= pickle.load(f)\n",
    "with open('/kaggle/working/val_descriptions.pkl','rb') as f:\n",
    "    val_descriptions= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:05.719920Z",
     "iopub.status.busy": "2023-07-13T09:21:05.719428Z",
     "iopub.status.idle": "2023-07-13T09:21:05.726633Z",
     "shell.execute_reply": "2023-07-13T09:21:05.725223Z",
     "shell.execute_reply.started": "2023-07-13T09:21:05.719884Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_imgs_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:05.736494Z",
     "iopub.status.busy": "2023-07-13T09:21:05.736066Z",
     "iopub.status.idle": "2023-07-13T09:21:05.744671Z",
     "shell.execute_reply": "2023-07-13T09:21:05.743468Z",
     "shell.execute_reply.started": "2023-07-13T09:21:05.736462Z"
    }
   },
   "outputs": [],
   "source": [
    "print(next(iter(train_descriptions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQ7lnBydK5RK"
   },
   "source": [
    "#### reoccuring vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:05.746886Z",
     "iopub.status.busy": "2023-07-13T09:21:05.746471Z",
     "iopub.status.idle": "2023-07-13T09:21:05.762217Z",
     "shell.execute_reply": "2023-07-13T09:21:05.761047Z",
     "shell.execute_reply.started": "2023-07-13T09:21:05.746853Z"
    },
    "id": "lLzfB5AwK7ch"
   },
   "outputs": [],
   "source": [
    "# making a vocabulary of the words that occur more than word_count_threshold time\n",
    "def create_reoccurring_vocab(descriptions, word_count_threshold = 10):\n",
    "    # Create a list of all the captions\n",
    "    all_captions = []\n",
    "    for key, val in descriptions.items():\n",
    "        for cap in val:\n",
    "            all_captions.append(cap)\n",
    "\n",
    "    # Consider only words which occur at least 10 times in the corpus\n",
    "    word_counts = {}\n",
    "    nsents = 0\n",
    "    for sent in all_captions:\n",
    "        nsents += 1\n",
    "        for w in sent.split(' '):\n",
    "            word_counts[w] = word_counts.get(w, 0) + 1\n",
    "\n",
    "    vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
    "\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:05.764122Z",
     "iopub.status.busy": "2023-07-13T09:21:05.763506Z",
     "iopub.status.idle": "2023-07-13T09:21:06.556355Z",
     "shell.execute_reply": "2023-07-13T09:21:06.555418Z",
     "shell.execute_reply.started": "2023-07-13T09:21:05.764079Z"
    },
    "id": "Y4gD67l5LBYL",
    "outputId": "3e2fc664-688b-4ad8-b50a-f23085527174"
   },
   "outputs": [],
   "source": [
    "vocab = create_reoccurring_vocab(train_descriptions, word_count_threshold = 5)\n",
    "sorted(vocab)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:06.558908Z",
     "iopub.status.busy": "2023-07-13T09:21:06.557702Z",
     "iopub.status.idle": "2023-07-13T09:21:06.649006Z",
     "shell.execute_reply": "2023-07-13T09:21:06.647778Z",
     "shell.execute_reply.started": "2023-07-13T09:21:06.558871Z"
    },
    "id": "Z0uEcCUFLG0k",
    "outputId": "4201f84b-a2c4-4cf6-9d76-4212947db110"
   },
   "outputs": [],
   "source": [
    "oov_token = '<UNK>'\n",
    "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n' # making sure all the last non digit non alphabet chars are removed\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(filters = filters, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(vocab)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('vocab_size :', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:06.650919Z",
     "iopub.status.busy": "2023-07-13T09:21:06.650516Z",
     "iopub.status.idle": "2023-07-13T09:21:06.660562Z",
     "shell.execute_reply": "2023-07-13T09:21:06.659179Z",
     "shell.execute_reply.started": "2023-07-13T09:21:06.650886Z"
    },
    "id": "2mHPTMbFLLjG"
   },
   "outputs": [],
   "source": [
    "ixtoword = {} # index to word dic\n",
    "wordtoix = {} # word to index dic\n",
    "\n",
    "tokenizer.word_index['<PAD0>'] = 0 # no word in vocab has index 0. but padding is indicated with 0\n",
    "wordtoix = tokenizer.word_index # word to index dic\n",
    "\n",
    "for w in tokenizer.word_index:\n",
    "    ixtoword[tokenizer.word_index[w]] = w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hzAM3BnLTCL"
   },
   "source": [
    "#### finding suitable length for sequences to use in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:21:06.662860Z",
     "iopub.status.busy": "2023-07-13T09:21:06.662206Z",
     "iopub.status.idle": "2023-07-13T09:21:06.894653Z",
     "shell.execute_reply": "2023-07-13T09:21:06.893005Z",
     "shell.execute_reply.started": "2023-07-13T09:21:06.662824Z"
    },
    "id": "1CMHNDiRLQBa",
    "outputId": "2aca959a-c228-4f92-e201-a73c49db8594"
   },
   "outputs": [],
   "source": [
    "# finding the maximum length of questions and answers\n",
    "# because there are senteces with unusually long lengths,\n",
    "# we caculate the max length that p% of data can be placed in\n",
    "def max_length(desc,p):\n",
    "    all_desc = []\n",
    "    # Create a list of all the captions\n",
    "    for i in desc:\n",
    "        for j in desc[i]:\n",
    "            all_desc.append(j)\n",
    "\n",
    "    length_all_desc = list(len(d.split()) for d in all_desc)\n",
    "\n",
    "    print('percentile {} of len of questions: {}'.format(p,np.percentile(length_all_desc, p)))\n",
    "    print('longest sentence: ', max(length_all_desc))\n",
    "\n",
    "    return int(np.percentile(length_all_desc, p))\n",
    "\n",
    "max_length = max_length(train_descriptions,90)\n",
    "\n",
    "print('max-len answer for training: ', max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxR5dmDyLne2"
   },
   "source": [
    "#### feature extractor model Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:32:00.113755Z",
     "iopub.status.busy": "2023-07-13T09:32:00.113094Z",
     "iopub.status.idle": "2023-07-13T09:32:04.032763Z",
     "shell.execute_reply": "2023-07-13T09:32:04.031004Z",
     "shell.execute_reply.started": "2023-07-13T09:32:00.113707Z"
    },
    "id": "YLfasZJVLj_X"
   },
   "outputs": [],
   "source": [
    "xception = Xception()\n",
    "extractor = Model(inputs=xception.inputs, outputs=xception.layers[-2].output) # removing 2 last fully connected layers\n",
    "print(extractor.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:32:04.035898Z",
     "iopub.status.busy": "2023-07-13T09:32:04.035309Z",
     "iopub.status.idle": "2023-07-13T09:32:04.046582Z",
     "shell.execute_reply": "2023-07-13T09:32:04.045483Z",
     "shell.execute_reply.started": "2023-07-13T09:32:04.035849Z"
    },
    "id": "n1a77SXuLueD"
   },
   "outputs": [],
   "source": [
    "def extract_features(description, model, inpute_size = (299,299)):\n",
    "    directory = '/content/flickr30k_images/flickr30k_images'\n",
    "    features = {}\n",
    "    i = 0\n",
    "    for name in description:\n",
    "        progressBar(value=i,endvalue=len(descriptions))\n",
    "        i +=1\n",
    "        filename =os.path.join(directory, name+'.jpg')\n",
    "        image = load_img(filename, target_size=inpute_size)\n",
    "        image = img_to_array(image)\n",
    "        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        image = preprocess_input(image)\n",
    "        feature = model.predict(image, verbose=0)\n",
    "        image_id = name.split('.')[0]\n",
    "        features[image_id] = feature.reshape(2048)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12t4S53DMJIi",
    "outputId": "edf7d3dc-04ea-44fe-9a96-776148a6f480"
   },
   "source": [
    "train_features = extract_features(train_descriptions, extractor)\n",
    "\n",
    "pickle.dump(train_features, open('train_features.pkl', 'wb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:32:04.048455Z",
     "iopub.status.busy": "2023-07-13T09:32:04.048096Z",
     "iopub.status.idle": "2023-07-13T09:32:06.790699Z",
     "shell.execute_reply": "2023-07-13T09:32:06.788756Z",
     "shell.execute_reply.started": "2023-07-13T09:32:04.048425Z"
    },
    "id": "aMHy-pwHFekY"
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/input/xception-feat/train_features.pkl','rb') as f:\n",
    "    t= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:32:13.707062Z",
     "iopub.status.busy": "2023-07-13T09:32:13.706034Z",
     "iopub.status.idle": "2023-07-13T09:32:13.741299Z",
     "shell.execute_reply": "2023-07-13T09:32:13.739738Z",
     "shell.execute_reply.started": "2023-07-13T09:32:13.707022Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features={}\n",
    "for name in train_imgs_names:\n",
    "    train_features[name]=t[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:32:14.938259Z",
     "iopub.status.busy": "2023-07-13T09:32:14.936909Z",
     "iopub.status.idle": "2023-07-13T09:32:14.949675Z",
     "shell.execute_reply": "2023-07-13T09:32:14.948649Z",
     "shell.execute_reply.started": "2023-07-13T09:32:14.938181Z"
    }
   },
   "outputs": [],
   "source": [
    "test_features={}\n",
    "for name in test_imgs_names:\n",
    "    test_features[name]=t[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:32:15.935263Z",
     "iopub.status.busy": "2023-07-13T09:32:15.933966Z",
     "iopub.status.idle": "2023-07-13T09:32:15.942149Z",
     "shell.execute_reply": "2023-07-13T09:32:15.940892Z",
     "shell.execute_reply.started": "2023-07-13T09:32:15.935194Z"
    }
   },
   "outputs": [],
   "source": [
    "val_features={}\n",
    "for name in val_imgs_names:\n",
    "    val_features[name]=t[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:32:16.519079Z",
     "iopub.status.busy": "2023-07-13T09:32:16.518642Z",
     "iopub.status.idle": "2023-07-13T09:32:16.527309Z",
     "shell.execute_reply": "2023-07-13T09:32:16.525676Z",
     "shell.execute_reply.started": "2023-07-13T09:32:16.519046Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train_features),len(test_features),len(val_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyMZ-dcRM6qP"
   },
   "source": [
    "#### Data Genarator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:32:19.153372Z",
     "iopub.status.busy": "2023-07-13T09:32:19.152906Z",
     "iopub.status.idle": "2023-07-13T09:32:19.164960Z",
     "shell.execute_reply": "2023-07-13T09:32:19.164077Z",
     "shell.execute_reply.started": "2023-07-13T09:32:19.153339Z"
    },
    "id": "KVV3TKxiM2Lb"
   },
   "outputs": [],
   "source": [
    "# outputs a batch of captions-pictures\n",
    "def data_generator(descriptions, photos):\n",
    "    X1, X2, y = [], [], []\n",
    "    n=0\n",
    "    # loop for ever over images\n",
    "    while 1:\n",
    "        for key, desc_list in descriptions.items():\n",
    "            n+=1\n",
    "            # retrieve the photo feature\n",
    "            photo = photos[key]\n",
    "            for desc in desc_list:\n",
    "                # find the index of each word of the caption in vocabulary\n",
    "                seq = tokenizer.texts_to_sequences(desc.split())\n",
    "                # split one sequence into multiple X, y pairs\n",
    "                # Each step of the following for loop selects one word\n",
    "                # from the caption, consider that word as y and\n",
    "                # all the words before that will be the X\n",
    "                for i in range(1, len(seq)):\n",
    "                    # split into input and output pair\n",
    "                    in_seq, out_seq = seq[:i], seq[i] # words until i are inseq word i is outseq\n",
    "                    # pad input sequence\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "\n",
    "                    X1.append(photo)\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "            # yield the batch data\n",
    "            if n == batch_size:\n",
    "                yield [[np.array(X1), np.array(X2).squeeze(axis=-1)], np.array(y).squeeze(axis=-1)]\n",
    "                X1, X2, y = list(), list(), list()\n",
    "                n=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:32:20.021841Z",
     "iopub.status.busy": "2023-07-13T09:32:20.021119Z",
     "iopub.status.idle": "2023-07-13T09:32:20.161110Z",
     "shell.execute_reply": "2023-07-13T09:32:20.160078Z",
     "shell.execute_reply.started": "2023-07-13T09:32:20.021804Z"
    },
    "id": "oWUv44-2Mq5I",
    "outputId": "35ecef2a-7a82-4e67-e4c8-ec72201d022e"
   },
   "outputs": [],
   "source": [
    "d = next(data_generator(train_descriptions, train_features))\n",
    "d[0][0].shape, d[0][1].shape, d[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C45khuwqGCAM"
   },
   "source": [
    "#### Word Emeddings glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:32:22.031068Z",
     "iopub.status.busy": "2023-07-13T09:32:22.030356Z",
     "iopub.status.idle": "2023-07-13T09:32:22.384600Z",
     "shell.execute_reply": "2023-07-13T09:32:22.383314Z",
     "shell.execute_reply.started": "2023-07-13T09:32:22.031033Z"
    },
    "id": "CL2d_7nUlOax"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "file_url = \"https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip\"\n",
    "\n",
    "r = requests.get(file_url, stream = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:32:27.084672Z",
     "iopub.status.busy": "2023-07-13T09:32:27.084191Z",
     "iopub.status.idle": "2023-07-13T09:32:42.465278Z",
     "shell.execute_reply": "2023-07-13T09:32:42.463912Z",
     "shell.execute_reply.started": "2023-07-13T09:32:27.084613Z"
    },
    "id": "cVukEVB1ldoC"
   },
   "outputs": [],
   "source": [
    "with open(\"/kaggle/working/glove.6B.zip\", \"wb\") as file:\n",
    "    for block in r.iter_content(chunk_size = 1024):\n",
    "         if block:\n",
    "                file.write(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:32:46.203268Z",
     "iopub.status.busy": "2023-07-13T09:32:46.202845Z",
     "iopub.status.idle": "2023-07-13T09:33:13.850766Z",
     "shell.execute_reply": "2023-07-13T09:33:13.849662Z",
     "shell.execute_reply.started": "2023-07-13T09:32:46.203238Z"
    },
    "id": "UNOcfypKGT3B",
    "outputId": "ad8af65e-1a8c-4643-9231-a966a93e71ca"
   },
   "outputs": [],
   "source": [
    "!unzip /kaggle/working/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:33:33.532613Z",
     "iopub.status.busy": "2023-07-13T09:33:33.532163Z",
     "iopub.status.idle": "2023-07-13T09:33:33.547120Z",
     "shell.execute_reply": "2023-07-13T09:33:33.545430Z",
     "shell.execute_reply.started": "2023-07-13T09:33:33.532577Z"
    },
    "id": "kHWw7UnMGAkL"
   },
   "outputs": [],
   "source": [
    "def make_embedding_layer(embedding_dim=50, glove=True):\n",
    "    if glove == False:\n",
    "        print('Just a zero matrix loaded')\n",
    "        embedding_matrix = np.zeros((vocab_size, embedding_dim)) # just a zero matrix\n",
    "    else:\n",
    "        glove_dir = '/kaggle/working/'\n",
    "        embeddings_index = {}\n",
    "        f = open(os.path.join(glove_dir, 'glove.6B.'+str(embedding_dim)+'d.txt'), encoding=\"utf-8\")\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "        f.close()\n",
    "        # Get x-dim dense vector for each of the vocab_rocc\n",
    "        embedding_matrix = np.zeros((vocab_size, embedding_dim)) # to import as weights for Keras Embedding layer\n",
    "        for word, i in wordtoix.items():\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                # Words not found in the embedding index will be all zeros\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        print('GloVe loaded!')\n",
    "\n",
    "    embedding_layer = Embedding(vocab_size, embedding_dim, mask_zero=True, trainable=False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([embedding_matrix])\n",
    "\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:33:34.785448Z",
     "iopub.status.busy": "2023-07-13T09:33:34.784982Z",
     "iopub.status.idle": "2023-07-13T09:33:42.274095Z",
     "shell.execute_reply": "2023-07-13T09:33:42.272951Z",
     "shell.execute_reply.started": "2023-07-13T09:33:34.785417Z"
    },
    "id": "-Nd5a2rAGMj2",
    "outputId": "493da2d9-e7fd-4256-8a3f-dcd1742a9899"
   },
   "outputs": [],
   "source": [
    "# in order to make model faster, I load embd outside the make_model\n",
    "embedding_layer = make_embedding_layer(emb_dim, glove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVaDe9e_Gxcn"
   },
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:33:45.035440Z",
     "iopub.status.busy": "2023-07-13T09:33:45.034951Z",
     "iopub.status.idle": "2023-07-13T09:33:45.043222Z",
     "shell.execute_reply": "2023-07-13T09:33:45.041973Z",
     "shell.execute_reply.started": "2023-07-13T09:33:45.035405Z"
    },
    "id": "MZAE9GwvG2HS"
   },
   "outputs": [],
   "source": [
    "def masked_loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = K.sparse_categorical_crossentropy(real, pred, from_logits= False) # sparse cat gets pred classes in 'int' form\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RBtmqf0G_rL"
   },
   "source": [
    "#### Constructing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:33:46.545221Z",
     "iopub.status.busy": "2023-07-13T09:33:46.544737Z",
     "iopub.status.idle": "2023-07-13T09:33:46.556586Z",
     "shell.execute_reply": "2023-07-13T09:33:46.555711Z",
     "shell.execute_reply.started": "2023-07-13T09:33:46.545184Z"
    },
    "id": "PGvkRZrEG4dZ"
   },
   "outputs": [],
   "source": [
    "from keras.layers import RepeatVector\n",
    "def make_model(embedding ,dout= 0.2, feature_size= 2048, units= 256):\n",
    "\n",
    "    features = Input(shape=(feature_size,)) # output size of feature extractor\n",
    "    X_fe_one_dim = Dense(units, activation='relu')(features) # because i have used bidirectional LSTM, the number of units should\n",
    "                                                   # become double here in order for the add function to work\n",
    "    X_fe = RepeatVector(max_length)(X_fe_one_dim)\n",
    "    X_fe = Dropout(dout)(X_fe)\n",
    "\n",
    "    seq = Input(shape=(max_length,))\n",
    "    X_seq = embedding(seq)\n",
    "    X_seq = Lambda(lambda x: x, output_shape=lambda s:s)(X_seq) # remove mask from the embedding cause concat doesn't support it\n",
    "    X_seq = Dropout(dout)(X_seq)\n",
    "    X_seq = Concatenate(name='concat_features_word_embeddings', axis=-1)([X_fe,X_seq])\n",
    "    X_seq = GRU(units, return_sequences=True)(X_seq,initial_state=X_fe_one_dim) # passing features as init_state\n",
    "    X_seq = Dropout(dout + 0.2)(X_seq)\n",
    "    X_seq = GRU(units, return_sequences=False)(X_seq)\n",
    "\n",
    "    outputs = Dense(vocab_size, activation='softmax')(X_seq)\n",
    "\n",
    "    # merge the two input models\n",
    "    model = Model(inputs=[features, seq], outputs = outputs, name='model_with_features_each_step')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:33:48.533238Z",
     "iopub.status.busy": "2023-07-13T09:33:48.531415Z",
     "iopub.status.idle": "2023-07-13T09:33:49.361299Z",
     "shell.execute_reply": "2023-07-13T09:33:49.359668Z",
     "shell.execute_reply.started": "2023-07-13T09:33:48.533165Z"
    },
    "id": "peWiPjW-G8ij",
    "outputId": "e04b185a-1d40-4090-98fb-b7fee0be07df"
   },
   "outputs": [],
   "source": [
    "model = make_model(embedding_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:33:50.578951Z",
     "iopub.status.busy": "2023-07-13T09:33:50.578480Z",
     "iopub.status.idle": "2023-07-13T09:33:50.871918Z",
     "shell.execute_reply": "2023-07-13T09:33:50.870919Z",
     "shell.execute_reply.started": "2023-07-13T09:33:50.578917Z"
    },
    "id": "TsBTLj9uHv4Y",
    "outputId": "4f3b6940-681d-4c4c-a767-f9c77b535523"
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model3.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:34:00.297638Z",
     "iopub.status.busy": "2023-07-13T09:34:00.297171Z",
     "iopub.status.idle": "2023-07-13T09:34:00.320946Z",
     "shell.execute_reply": "2023-07-13T09:34:00.319674Z",
     "shell.execute_reply.started": "2023-07-13T09:34:00.297586Z"
    },
    "id": "0C5cdyiVH8Gp"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=masked_loss_function, optimizer= 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:34:02.395254Z",
     "iopub.status.busy": "2023-07-13T09:34:02.394777Z",
     "iopub.status.idle": "2023-07-13T09:34:02.401807Z",
     "shell.execute_reply": "2023-07-13T09:34:02.399567Z",
     "shell.execute_reply.started": "2023-07-13T09:34:02.395217Z"
    },
    "id": "IVhJWy4iIAb7"
   },
   "outputs": [],
   "source": [
    "history={'loss':[], 'BLEU_val':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:34:03.206065Z",
     "iopub.status.busy": "2023-07-13T09:34:03.205550Z",
     "iopub.status.idle": "2023-07-13T09:34:03.218704Z",
     "shell.execute_reply": "2023-07-13T09:34:03.217518Z",
     "shell.execute_reply.started": "2023-07-13T09:34:03.206027Z"
    },
    "id": "9BbwtLPaIGQ8"
   },
   "outputs": [],
   "source": [
    "# generate a description for an image greedy way\n",
    "def generate_desc(model, photo_fe, inference= False):\n",
    "    # seed the generation process\n",
    "    in_text = start_token\n",
    "    # iterate over the whole length of the sequence\n",
    "    # generate one word at each iteratoin of the loop\n",
    "    # appends the new word to a list and makes the whole sentence\n",
    "    for i in range(max_length):\n",
    "        # integer encode input sequence\n",
    "        sequence = tokenizer.texts_to_sequences(in_text.split()) #[wordtoix[w] for w in in_text.split() if w in wordtoix]\n",
    "        # pad input\n",
    "        photo_fe = photo_fe.reshape((1,2048))\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length).reshape((1,max_length))\n",
    "        # predict next word\n",
    "        yhat = model.predict([photo_fe,sequence], verbose=0)\n",
    "        # convert probability to integer\n",
    "        yhat = np.argmax(yhat)\n",
    "        # map integer to word\n",
    "        word = ixtoword[yhat]\n",
    "        # stop if we cannot map the word\n",
    "        if word is None:\n",
    "            break\n",
    "        # append as input for generating the next v\n",
    "        in_text += ' ' + word\n",
    "        # stop if we predict the end of the sequence\n",
    "        if word == end_token:\n",
    "            break\n",
    "\n",
    "    if inference == True:\n",
    "        in_text = in_text.split()\n",
    "        if len(in_text) == max_length:\n",
    "            in_text = in_text[1:] # if it is already at max len and endseq hasn't appeared\n",
    "        else:\n",
    "            in_text = in_text[1:-1]\n",
    "        in_text = ' '.join(in_text)\n",
    "\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:34:03.808261Z",
     "iopub.status.busy": "2023-07-13T09:34:03.807054Z",
     "iopub.status.idle": "2023-07-13T09:34:03.823173Z",
     "shell.execute_reply": "2023-07-13T09:34:03.821716Z",
     "shell.execute_reply.started": "2023-07-13T09:34:03.808218Z"
    },
    "id": "gCDupiOPIKXk"
   },
   "outputs": [],
   "source": [
    "def beam_search_pred(model, pic_fe, wordtoix, K_beams = 3, log = False):\n",
    "    start = [wordtoix[start_token]]\n",
    "\n",
    "    start_word = [[start, 0.0]]\n",
    "\n",
    "    while len(start_word[0][0]) < max_length:\n",
    "        temp = []\n",
    "        for s in start_word:\n",
    "            sequence  = pad_sequences([s[0]], maxlen=max_length).reshape((1,max_length)) #sequence of most probable words\n",
    "                                                                                         # based on the previous steps\n",
    "            preds = model.predict([pic_fe.reshape(1,2048), sequence],verbose=0)\n",
    "            word_preds = np.argsort(preds[0])[-K_beams:] # sort predictions based on the probability, then take the last\n",
    "                                                         # K_beams items. words with the most probs\n",
    "            # Getting the top <K_beams>(n) predictions and creating a\n",
    "            # new list so as to put them via the model again\n",
    "            for w in word_preds:\n",
    "\n",
    "                next_cap, prob = s[0][:], s[1]\n",
    "                next_cap.append(w)\n",
    "                if log:\n",
    "                    prob += np.log(preds[0][w]) # assign a probability to each K words4\n",
    "                else:\n",
    "                    prob += preds[0][w]\n",
    "                temp.append([next_cap, prob])\n",
    "        start_word = temp\n",
    "        # Sorting according to the probabilities\n",
    "        start_word = sorted(start_word, reverse=False, key=lambda l: l[1])\n",
    "\n",
    "        # Getting the top words\n",
    "        start_word = start_word[-K_beams:]\n",
    "\n",
    "    start_word = start_word[-1][0]\n",
    "    captions_ = [ixtoword[i] for i in start_word]\n",
    "\n",
    "    final_caption = []\n",
    "\n",
    "    for i in captions_:\n",
    "        if i != end_token:\n",
    "            final_caption.append(i)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    final_caption = ' '.join(final_caption[1:])\n",
    "    return final_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:34:04.515894Z",
     "iopub.status.busy": "2023-07-13T09:34:04.515248Z",
     "iopub.status.idle": "2023-07-13T09:34:04.530140Z",
     "shell.execute_reply": "2023-07-13T09:34:04.528423Z",
     "shell.execute_reply.started": "2023-07-13T09:34:04.515836Z"
    },
    "id": "J11d5tL9IO5H"
   },
   "outputs": [],
   "source": [
    "# calculating BLEU score of predictions\n",
    "def evaluate_model(model, descriptions, photos_fe, K_beams= 3, log=False):\n",
    "    actual, predicted = list(), list()\n",
    "    b1=0\n",
    "    b2=0\n",
    "    b3=0\n",
    "    b4=0\n",
    "    # step over the whole set\n",
    "    i=0\n",
    "    for key, desc_list in descriptions.items():\n",
    "        # generate description\n",
    "        i+=1\n",
    "        progressBar(i, len(descriptions), bar_length=20,job='Evaluating')\n",
    "        if K_beams == 1:\n",
    "            yhat = generate_desc(model, photos_fe[key])\n",
    "        else:\n",
    "            yhat=beam_search_pred(model, photos_fe[key], wordtoix, K_beams = K_beams,log=log)\n",
    "\n",
    "        # store actual and predicted\n",
    "        references = [d.split() for d in desc_list]\n",
    "        actual.append(references)\n",
    "        predicted.append(yhat.split())\n",
    "\n",
    "    # calculate BLEU score\n",
    "    b1=corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
    "    b2=corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
    "    b3=corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0))\n",
    "    b4=corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    print('\\n')\n",
    "    print('BLEU-1: %f' % b1)\n",
    "    print('BLEU-2: %f' % b2)\n",
    "    print('BLEU-3: %f' % b3)\n",
    "    print('BLEU-4: %f' % b4)\n",
    "    return [b1,b2,b3,b4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:34:32.195506Z",
     "iopub.status.busy": "2023-07-13T09:34:32.195051Z",
     "iopub.status.idle": "2023-07-13T09:34:32.203302Z",
     "shell.execute_reply": "2023-07-13T09:34:32.201553Z",
     "shell.execute_reply.started": "2023-07-13T09:34:32.195472Z"
    },
    "id": "_rBr1fs-IVIS"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "Reduce_lr= ReduceLROnPlateau(monitor='loss', factor=0.9, patience=5, verbose=0, mode='auto', min_delta=0.0001, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:34:34.798871Z",
     "iopub.status.busy": "2023-07-13T09:34:34.798382Z",
     "iopub.status.idle": "2023-07-13T09:34:46.965912Z",
     "shell.execute_reply": "2023-07-13T09:34:46.964415Z",
     "shell.execute_reply.started": "2023-07-13T09:34:34.798836Z"
    },
    "id": "rl7ZiccjIYbC"
   },
   "outputs": [],
   "source": [
    "def test(i=np.random.randint(len(test_features)), j=np.random.randint(len(test_features)),\n",
    "         k=np.random.randint(len(test_features)), q=np.random.randint(len(test_features)), show_pic=False):\n",
    "    print('====')\n",
    "    pic = list(test_features.keys())[i]\n",
    "    fe = test_features[pic].reshape((1,2048))\n",
    "    if show_pic:\n",
    "        x=plt.imread('/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/'+pic+'.jpg')\n",
    "        plt.imshow(x)\n",
    "        plt.show()\n",
    "    print(\"Greedy:\",generate_desc(model, fe, inference=True))\n",
    "\n",
    "    pic = list(test_features.keys())[j]\n",
    "    fe = test_features[pic].reshape((1,2048))\n",
    "    if show_pic:\n",
    "        x=plt.imread('/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/'+pic+'.jpg')\n",
    "        plt.imshow(x)\n",
    "        plt.show()\n",
    "    print(\"Greedy:\",generate_desc(model, fe, inference=True))\n",
    "\n",
    "    pic = list(test_features.keys())[k]\n",
    "    fe = test_features[pic].reshape((1,2048))\n",
    "    if show_pic:\n",
    "        x=plt.imread('/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/'+pic+'.jpg')\n",
    "        plt.imshow(x)\n",
    "        plt.show()\n",
    "    print(\"Greedy:\", generate_desc(model, fe, inference=True))\n",
    "    pic = list(test_features.keys())[q]\n",
    "    fe = test_features[pic].reshape((1,2048))\n",
    "    if show_pic:\n",
    "        x=plt.imread('/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/'+pic+'.jpg')\n",
    "        plt.imshow(x)\n",
    "        plt.show()\n",
    "    print(\"Greedy:\",generate_desc(model, fe, inference=True))\n",
    "\n",
    "    print('====')\n",
    "\n",
    "\n",
    "test(show_pic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:35:01.934426Z",
     "iopub.status.busy": "2023-07-13T09:35:01.933950Z",
     "iopub.status.idle": "2023-07-13T09:35:01.940828Z",
     "shell.execute_reply": "2023-07-13T09:35:01.939526Z",
     "shell.execute_reply.started": "2023-07-13T09:35:01.934391Z"
    },
    "id": "OxdYr4drIm5x"
   },
   "outputs": [],
   "source": [
    "steps = len(train_descriptions)//batch_size\n",
    "generator = data_generator(train_descriptions, train_features)\n",
    "ep=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T11:25:05.359830Z",
     "iopub.status.busy": "2023-07-13T11:25:05.359166Z",
     "iopub.status.idle": "2023-07-13T11:25:05.753425Z",
     "shell.execute_reply": "2023-07-13T11:25:05.752188Z",
     "shell.execute_reply.started": "2023-07-13T11:25:05.359794Z"
    }
   },
   "outputs": [],
   "source": [
    "model1=load_model('/kaggle/input/modeling/final_model (1).h5',compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-13T09:35:46.555683Z",
     "iopub.status.busy": "2023-07-13T09:35:46.555148Z",
     "iopub.status.idle": "2023-07-13T09:36:16.936375Z",
     "shell.execute_reply": "2023-07-13T09:36:16.934122Z",
     "shell.execute_reply.started": "2023-07-13T09:35:46.555647Z"
    },
    "id": "5HQcoBYJIxDD",
    "outputId": "872d1606-f492-48ef-c023-e53304445f12"
   },
   "outputs": [],
   "source": [
    "for i in range(1, 51):\n",
    "\n",
    "    print('Epoch :',i,'\\n')\n",
    "    # fit for one epoch\n",
    "    h = model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1, callbacks=[Reduce_lr] )\n",
    "    ep = i + 1\n",
    "    history['loss'].append(h.history['loss'])\n",
    "\n",
    "    # save model every 3 epochs\n",
    "    if i % 10 == 0:\n",
    "        test()\n",
    "        model.save_weights(snaphot_folder+'/model_' + str(i) + '.h5')\n",
    "\n",
    "    print('\\n','='*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belus= evaluate_model(model, val_descriptions, val_features, K_beams=1)\n",
    "history['BLEU_val'].append(belus,50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T00:57:07.236219Z",
     "iopub.status.busy": "2023-07-09T00:57:07.235822Z",
     "iopub.status.idle": "2023-07-09T00:57:07.354538Z",
     "shell.execute_reply": "2023-07-09T00:57:07.353261Z",
     "shell.execute_reply.started": "2023-07-09T00:57:07.236188Z"
    },
    "id": "LosE3h48LbVM"
   },
   "outputs": [],
   "source": [
    "model.save('/kaggle/working/final_model+.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T00:59:10.557221Z",
     "iopub.status.busy": "2023-07-09T00:59:10.556806Z",
     "iopub.status.idle": "2023-07-09T00:59:10.563648Z",
     "shell.execute_reply": "2023-07-09T00:59:10.562512Z",
     "shell.execute_reply.started": "2023-07-09T00:59:10.557190Z"
    }
   },
   "outputs": [],
   "source": [
    "len(history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T00:59:41.332106Z",
     "iopub.status.busy": "2023-07-09T00:59:41.331670Z",
     "iopub.status.idle": "2023-07-09T00:59:41.340831Z",
     "shell.execute_reply": "2023-07-09T00:59:41.339695Z",
     "shell.execute_reply.started": "2023-07-09T00:59:41.332060Z"
    }
   },
   "outputs": [],
   "source": [
    "history['BLEU_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CIH-Bwj6L72t"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model1=load_model('/kaggle/working/full_model.h5',compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss=masked_loss_function, optimizer= 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-09T00:57:25.022262Z",
     "iopub.status.busy": "2023-07-09T00:57:25.021219Z",
     "iopub.status.idle": "2023-07-09T00:57:45.828679Z",
     "shell.execute_reply": "2023-07-09T00:57:45.827729Z",
     "shell.execute_reply.started": "2023-07-09T00:57:25.022212Z"
    }
   },
   "outputs": [],
   "source": [
    "test_image='/kaggle/input/flickr-image-dataset/flickr30k_images/flickr30k_images/1000092795.jpg'\n",
    "image = load_img(test_image, target_size=(299,299))\n",
    "image = img_to_array(image)\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "image = preprocess_input(image)\n",
    "fe = extractor.predict(image, verbose=0)\n",
    "fe = fe.reshape((1,2048))\n",
    "x=plt.imread(test_image)\n",
    "plt.imshow(x)\n",
    "plt.show()\n",
    "print(\"Greedy:\",generate_desc(model, fe, inference=True))\n",
    "print(\"Beam K= 3:\",beam_search_pred(model, fe, wordtoix, K_beams = 3, log=False))\n",
    "print(\"Beam K= 5:\",beam_search_pred(model, fe, wordtoix, K_beams = 5, log=False))\n",
    "print(\"Beam log K= 3:\",beam_search_pred(model, fe, wordtoix, K_beams = 3, log=True))\n",
    "print(\"Beam log K= 5:\",beam_search_pred(model, fe, wordtoix, K_beams = 5, log=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
